<html lang="en">
<head>
  <title>Tong Zhang's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Tong Zhang is an undergraduate researcher of deep learning.">
  <meta name="keywords" content="Tong Zhang, 张通, zhangtong, Zhang.Tong, Stone Zhang, Zhang. Stone, the-star-sea, Deep Learning, SUSTech, UCI, Computer Vision, Multimodal Learning">
  <meta name="author" content="Tong Zhang" />

  <link rel="stylesheet" href="stone.css">

  <style>
  .stone-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.stone-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/jpg" href="images/icons.jpg">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MJ3ND9PX0V"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MJ3ND9PX0V');
  </script>
</head>


<body class="stone-content" style="max-width:1000px">


<!-- !PAGE CONTENT! -->
<div class="stone-main" style="margin-left:150px">

<!--  &lt;!&ndash; Push down content on small screens &ndash;&gt;-->
<!--  <div class="stone-hide-large" style="margin-top:83px"></div>-->

<!-- The Home Section -->
    <div class="stone-container stone-center stone-padding-16" id="home">

       <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/ne.jpeg">
      <h1>Stone Tong ZHANG </h1>

        <p class="stone-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am a  MS student of  <a href="https://uci.edu/"> University of California, Irvine</a>
         and gain Bachelor of Computer Science and Engineering from <a href="https://www.sustech.edu.cn/en/">Southern University of Science and Technology</a>.
          My research interests include <b>Computer Vision</b> and <b>Multimodal Learning</b>. I am now deeply collaborate with Prof. <a href="https://www.colips.org/~eleliha/">Haizhou Li</a> at CUHK-SZ.<b>
           </b>Feel free to contact me at any time.
        <p class="stone-center">
          <a href="mailto:tongz27@uci.edu">Email</a>
      <a href="https://github.com/the-star-sea">Github</a>
      <a href="https://www.linkedin.com/in/tong-zhang-stone/">Linkedin</a>
      <a href="./cv.pdf">CV</a>
        <a href="./research_statement.pdf">Research Statement</a>
<!--      <a href="./transcript.pdf">Transcript</a>-->
        </p>
  </div>


 <div class="stone-container  stone-padding-16" id="education background">
<p><li> Sep. 2019-June 2023, "<a href="https://www.sustech.edu.cn/en/">Southern University of Science and Technology</a>", BEng, Computer Science and Engineering</li></p>
   <p><li> Sep. 2023-June 2024, "<a href="https://uci.edu/">University of California, Irvine</a>", M.S., Computer Engineering</li></p>

 </div>


    <div class="stone-container stone-padding-16" id="academic-projects">
        <h2 class="stone-text-theme">Academic Projects</h2>

        <h4 class="stone-text-bold"><a href="overdefense.pdf">Unintended Side Effects of Defense Mechanisms in Large Language Models</a></h4>
        <img src="images/llm_defense.png" style="width:96%">
          <h6><font style="font-family:Times New Roman ">Prof. <a href="https://www.colips.org/~eleliha/">Haizhou Li</a>, CUHK-Shenzhen <br> PyTorch, LaTeX</font></h6></font>
              <li>Conducted a comprehensive analysis of 11 defense mechanisms applied to 6 LLMs, evaluating their impact on model performance, over-refusal, and token overhead</li>
              <li>Proposed 9 <b>meta-defenders</b> to systematically analyze trade-offs between safety and utility in model responses</li>
              <li>Provided actionable insights on designing robust LLMs for safety-critical applications</li>


        <h4 class="stone-text-bold"><a href="https://arxiv.org/abs/2311.15543">Human-Readable SVG Generation with Vision Language Models</a></h4>
        <img src="images/svg.jpg" style="width:96%">
            <h6><font style="font-family:Times New Roman ">Assistant Prof. <a href="https://haohanwang.github.io/">Haohan Wang</a>, UIUC <br> PyTorch</font></h6></font>
                <li>Developed S²VG², an innovative method integrating vision language models for scalable vector graphics (SVG) generation</li>
                <li>Curated the SVG-SHAPE dataset to benchmark SVG generation and model reasoning capabilities</li>
                <li>Demonstrated state-of-the-art performance in SVG reasoning of LLMs and vision metrics </li>

        <h4 class="stone-text-bold"><a href="https://arxiv.org/abs/2311.06443">One-shot Controllable Head Avatar Creation</a></h4>
        <img src="images/CVTHead.jpg"  style="width:96%">
        <h6><font style="font-family:Times New Roman ">Prof. <a href="https://www.ics.uci.edu/~xhx/">Xiaohui Xie</a>, UCI <br> PyTorch</font></h6></font>
        <li>Pioneered CVTHead, a framework for point-based neural rendering from monocular images</li>
        <li>Conducted comprehensive benchmarks against leading methods for cross-identity reenactment</li>
        <li>Demonstrated state-of-the-art approaches on VoxCeleb1 and VoxCeleb2, while additionally improving efficiency (Accepted by WACV2024)</li>





      <h4><a href="https://arxiv.org/abs/2302.00673"> Trajectory Prediction and Driving Video Caption </a></h4>
        <img src="images/trajectory.jpg"  style="width:96%">
      <h6><font style="font-family:Times New Roman ">Assistant Prof. <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>, THU <br>NumPy, PyTorch</font></h6></font>
      <li> predicted trajectory on a new interactive motion dataset by AgentFormer and Trajectron++</li>
      <li>trained a novel end-to-end transformer generated description and explanation of the video</li>
      <li>demonstrated state-of-the-art performance  (a co-authored paper accepted to ICRA 2023)</li>
    </div>
<!--    <h4><a href="./odegan.pdf"> Facial Image Generation across  Age</a></h4>-->
<!--    <h6><font style="font-family:Times New Roman ">Associate Prof. <a href="https://yuzhanghk.github.io/">Yu Zhang</a>, SUSTech <br> PyTorch</font></h6></font>-->
<!--    <li> applied support vector machines to do latent manipulation linearly in StyleGAN</li>-->
<!--    <li>proposed a novel model to transform facial images continuously across age based on StyleGAN  and Neural ODE</li>-->
<!--    <li>applied an age estimator to supervise Generator and ensure the identity and age of face</li>-->

<!--    -->


  <div class="stone-container stone-padding-16" id="project experience">
      <h2 class="stone-text-theme">Capstone Projects</h2>

    <h4><a href="https://github.com/the-star-sea/fastcnn">Inference Acceleration for Face Detection Models</a> </h4>
    <h6><font style="font-family:Times New Roman ">C/C++ Programming and Design (CS205), SUSTech<br>C++, AVX </font> </h6></font>
    <li> re-implemented convolutional layer, fully connected layer and pooling layer by C++ and AVX</li>
    <li>improved the inference speed by 60 times via replacement of operators</li>

    <h4><a href="https://github.com/the-star-sea/CARP_gene">A Local Search Heuristic for the Capacitated Arc Routing Problem (CARP) </a></h4>
    <h6><font style="font-family:Times New Roman ">Artificial Intelligence (CS303), SUSTech<br>Python</font></h6></font>
    <li>proposed a new local search algorithm for CARP and accelerated it by multiprocessing</li>
    <li>achieved the best performance in the online judge among more than 150 students</li>

<!--    <h4>A Tremor Detection Android APP </h4>-->
<!--    <h6><font style="font-family:Times New Roman ">Senior Project (EECS 159A), UCI<br>Kotlin, NumPy</font></h6></font>-->
<!--    <li>designed the whole architecture and implemented the signal process module (FFT, Decision Tree)</li>-->
<!--    <li>deployed a hand pose estimation model in Android through TFlite</li>-->

  </div>

  <div class="stone-container stone-padding-16" id="professional experience">
    <h2>Professional Experience</h2>
    <h4><a href=https://gist.github.com/the-star-sea/27fbdb0a6e93e1ba1735c4c1e9740aa2>Lightweight OCR Models for OpenCV</a></h4>
    <h6><font style="font-family:Times New Roman "> OpenCV@<a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a>  <br>PyTorch, ONNX, C++</font></h6></font>
    <li> implemented the detection part of PP-OCRv2 model in OpenCV Zoo by ONNX</li>
    <li>  implemented high level C++ API of PP-OCRv2 model in OpenCV</li>
    <li> implemented evaluation metrics of text detection (AP, Recall, Precision, Hmean) in OpenCV Zoo</li>

    <h4>Undergraduate Teaching Assistant </h4>
    <h5><font style="font-family:Times New Roman "> CS102B, SUSTech <br>Java</font></h5></font>

    <li> designed and graded half of assignments, final exam and project
    </li>
  </div>


    <div class="stone-container stone-padding-16" id="publications">
        <h2>Publications</h2>


            <li>
                <strong>Tong Zhang</strong>, Haoyang Liu, Peiyan Zhang, Yuxuan Cheng, and Haohan Wang,
                "<em>Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images with Vision Language Models</em>",
                Submitted to European Conference on Computer Vision (ECCV), 2024.
            </li>
            <li>
                Haoyu Ma, <strong>Tong Zhang</strong>, Shanlin Sun, Xiangyi Yan, Kun Han, and Xiaohui Xie,
                "<em>CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer</em>",
                IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024.
            </li>
            <li>
                Bu Jin, Xinyu Liu, Yupeng Zheng, Pengfei Li, Hao Zhao, <strong>Tong Zhang</strong>, Yuhang Zheng, Guyue Zhou, and Jingjing Liu,
                "<em>ADAPT: Action-aware Driving Caption Transformer</em>",
                IEEE International Conference on Robotics and Automation (ICRA), 2023.
            </li>

    </div>



    <div class="stone-container  stone-padding-16" id="skills">
    <h2>Expert Skills</h2>

      <li>Programming Languages: C++, Python, Java</li>
      <li>Libraries/Software: PyTorch, NumPy, Latex</li>
      <li>Knowledge: GAN, VAE, Transformer</li>


  </div>

  <div class="stone-container  stone-padding-16" id="facts">
    <h2>Facts about Me</h2>

      <li>Hometown: Wuhan</li>
      <li>Idol: Richard Feynman</li>
      <li>Dream: To be a great researcher and design influential software</li>
      <li>I enjoy finding potential topics from active discussions and am proud of my creativity.</li>

  </div >

  <div  id="map" style="max-width:256px; margin-left: auto; margin-right: auto;">
  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=Uw9d9XV4XuKkP9sbAxcddpIWFVUwQ-HJCJR6jiSl5_A&cl=ffffff&w=a"></script>
      <!-- Note to anyone copying the HTML for the following counter:
    the counter name ("username" on this page) must be unique.
    Otherwise different pages will increment the same counter. See
    http://stuff.mit.edu/doc/counter-howto.html. -->
      This page has been accessed
      <a href="http://stuff.mit.edu/doc/counter-howto.html"><img
              src="http://stuff.mit.edu/cgi/counter/tongzhang" alt="several"></a>
      times since  Jan. 10, 2023.
  </div>

  <!-- End page content -->
</div>

<script>

  document.οncοntextmenu=function(){return false;};
  document.onselectstart=function(){return false;};
  document.oncontextmenu = function () { return false; };


  window.onkeydown = window.onkeyup = window.onkeypress = function () {
    window.event.returnValue = false;
    return false;
  }

  document.onkeydown = function () {
    if (window.event && window.event.keyCode == 123) {
      event.keyCode = 0;
      event.returnValue = false;
      return false;
    }
  };




</script>

</body>
</html>
